<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Post Page 7</title>
    <link rel="stylesheet" href=".././style.css">
    <!--Box Icons-->
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
</head>
<body>
    <!--Header-->
    <header>
        <!--Nav-->
        <div class="nav container">
            <!--Logo-->
            <a href=".././index.html" class="logo"><span>IT</span>Blog</a>
            <!--Login button-->
            <a href="#" class="login">Login</a>
        </div>
    </header>
    <!--Post Content-->
    <section class="post-header">
        <div class="header-content post-container">
            <!--Back to home-->
            <a href=".././index.html" class="back-home">Back to Home Page</a>
            <!--Title-->
            <h1 class="header-title">OpenAI thinks superhuman AI is coming</h1>
            <img src=".././images/post-7.jpg" alt="" class="header-img">
        </div>
    </section>
    
    
    <!--Posts-->
    <section class="post-content post-container">
        <h2 class="sub-heading">AI</h2>
        <p class="post-text">While investors were preparing to go nuclear after Sam Altman’s unceremonious ouster from OpenAI and Altman was plotting his return to the company, the members of OpenAI’s Superalignment team were assiduously plugging along on the problem of how to control AI that’s smarter than humans. Or at least, that’s the impression they’d like to give.</p>
        <p class="post-text">This week, I took a call with three of the Superalignment team’s members — Collin Burns, Pavel Izmailov and Leopold Aschenbrenner — who were in New Orleans at NeurIPS, the annual machine learning conference, to present OpenAI’s newest work on ensuring that AI systems behave as intended.</p>
        <p class="post-text">OpenAI formed the Superalignment team in July to develop ways to steer, regulate and govern “superintelligent” AI systems — that is, theoretical systems with intelligence far exceeding that of humans. “Today, we can basically align models that are dumber than us, or maybe around human-level at most,” Burns said. “Aligning a model that’s actually smarter than us is much, much less obvious — how we can even do it?”</p>
        <p class="post-text">The Superalignment effort is being led by OpenAI co-founder and chief scientist Ilya Sutskever, which didn’t raise eyebrows in July — but certainly does now in light of the fact that Sutskever was among those who initially pushed for Altman’s firing. While some reporting suggests Sutskever is in a “state of limbo” following Altman’s return, OpenAI’s PR tells me that Sutskever is indeed — as of today, at least — still heading the Superalignment team. Superalignment is a bit of a touchy subject within the AI research community. Some argue that the subfield is premature; others imply that it’s a red herring.</p>
        <p class="post-text">While Altman has invited comparisons between OpenAI and the Manhattan Project, going so far as to assemble a team to probe AI models to protect against “catastrophic risks,” including chemical and nuclear threats, some experts say that there’s little evidence to suggest the startup’s technology will gain world-ending, human-outsmarting capabilities anytime soon — or ever. Claims of imminent superintelligence, these experts add, serve only to deliberately draw attention away from and distract from the pressing AI regulatory issues of the day, like algorithmic bias and AI’s tendency toward toxicity.</p>
    </section>

    <!--Share-->
    <div class="share post-container">
        <span class="share-title">Share this article</span>
        <div class="social">
            <a href="https://www.facebook.com/"><i class='bx bxl-facebook'></i></a>
            <a href="https://www.instagram.com/"><i class='bx bxl-instagram'></i></a>
            <a href="https://web.telegram.org/a/"><i class='bx bxl-telegram'></i></a>
            <a href="https://www.linkedin.com/"><i class='bx bxl-linkedin' ></i></a>
        </div>
    </div>
   
    
    <!--Footer-->
    <div class="footer container">
        <p>&#169; All Right Reserved</p>
        <div class="social">
            <a href="https://www.facebook.com/"><i class='bx bxl-facebook'></i></a>
            <a href="https://www.instagram.com/"><i class='bx bxl-instagram'></i></a>
            <a href="https://web.telegram.org/a/"><i class='bx bxl-telegram'></i></a>
            <a href="https://www.linkedin.com/"><i class='bx bxl-linkedin' ></i></a>
        </div>
    </div>

    <!--JQuery Link-->
    <script
  src="https://code.jquery.com/jquery-3.7.1.js"
  integrity="sha256-eKhayi8LEQwp4NKxN+CfCh+3qOVUtJn3QNZ0TciWLP4="
  crossorigin="anonymous"></script>

    <script src="./index.js"></script>
</body>
</html>